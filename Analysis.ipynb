{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c2aef5",
   "metadata": {},
   "source": [
    "## Anna Kaniowska - Cellphones & Accessories dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505a6c1",
   "metadata": {},
   "source": [
    "The goal of this project is to extract as much information form the data set that can be obtained here - http://snap.stanford.edu/data/amazon/Cell_Phones_&_Accessories.txt.gz (source: http://snap.stanford.edu/data/web-Amazon-links.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dd8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed to perform the analysis\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415de27",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A modified version of function available on the source page\n",
    "def parse(filename):\n",
    "    \"\"\"\n",
    "    Parses a gzipped text file and returns a list of dictionaries containing the parsed data.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The path to the gzipped text file to be parsed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing the parsed data.\n",
    "    \"\"\"\n",
    "    f = gzip.open(filename, 'rb')\n",
    "    entry = {}\n",
    "    data = []\n",
    "    for line in f:\n",
    "        l = line.decode('utf-8').strip()\n",
    "        colonPos = l.find(':')\n",
    "        if colonPos == -1:\n",
    "            data.append(entry)\n",
    "            entry = {}\n",
    "            continue\n",
    "        eName = l[:colonPos]\n",
    "        rest = l[colonPos+2:]\n",
    "        entry[eName] = rest\n",
    "    data.append(entry)\n",
    "    return data\n",
    "\n",
    "# Loading the dataset\n",
    "data = parse('Cell_Phones_&_Accessories.txt.gz')\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff9746",
   "metadata": {},
   "source": [
    "#### Getting to know the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c0f42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f536042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447791f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the dataset is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780ac8a",
   "metadata": {},
   "source": [
    "Taking a first look at the data, it is visible that it shows the reviews that customers gave to the products. The products are mainly cellphones and their accesories. The dataset is big - almost 79 000 rows is a significant amount of data. 10 columns provide information about the rated product, the customer and their opinion on the product. When it comes to technical details - it is necessary to change 'unknown' values to NaN in order to prepare data to further analysis. Checking the dataset for duplicated rows and dropping existing ones is also necessary because this is something that cannot be seen at first glance. Another conclusion is that the types of the columns are not necessarily correct (e.g. product/price should be stored as float), it is also needed to be corrected.\n",
    "\n",
    "## Feature Engineering & Exploratory Data Analysis\n",
    "\n",
    "#### Checking for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba20d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There is {df.duplicated().sum()} duplicated rows in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edc49b",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"unknown\", np.nan, inplace=True)\n",
    "\n",
    "# Analyzing the missing values occurences\n",
    "print(\"Missing values occurences:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Checking anonymous reviews (those where userId and profileName is missing)\n",
    "anon_reviews_perc = df['review/userId'].isna().sum()/df.shape[0] * 100\n",
    "print(f\"{anon_reviews_perc:.2f}% of the reviews are anonymously submitted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d2f306",
   "metadata": {},
   "source": [
    "The first conclusion is one row that can be safely deleted in each column (it is very likely that it is the same row for each of the columns). \\\n",
    "The second conclusion refers to anonymous reviews. When missing values are less than 5% of given feature, they can be safely deleted without having impact on further analysis. For now the data will be divided into to sets - first with anonymous reviews and second with named reviews. It may be useful to further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac16955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting columns with 1 missing value\n",
    "cols = ['product/productId', 'product/title', 'review/helpfulness', 'review/score', 'review/time', \\\n",
    "        'review/summary', 'review/text']\n",
    "df = df.dropna(subset=cols)\n",
    "print(f\"Shape of the dataset after dropping NaNs: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131debf",
   "metadata": {},
   "source": [
    "As expected, only one row of the data was deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc67d5e0",
   "metadata": {},
   "source": [
    "Before dividing dataset into two separate dataset it would be useful to correct the columns' types.\n",
    "\n",
    "#### Correcting columns types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product/price'] = pd.to_numeric(df['product/price'], errors='coerce')\n",
    "df['review/score'] = pd.to_numeric(df['review/score'], errors='coerce')\n",
    "df['review/time'] = pd.to_datetime(df['review/time'].astype(float), unit='s')\n",
    "\n",
    "def handle_helpfulness(x):\n",
    "    \"\"\"\n",
    "    Converts the string representation of helpfulness scores to a float value between 0 and 1.\n",
    "\n",
    "    Parameters:\n",
    "        helpfulness (str): The string representation of helpfulness scores, in the format \"x/y\",\n",
    "        where \"x\" is the number of users who found the review helpful and \"y\" is the total number of votes.\n",
    "\n",
    "    Returns:\n",
    "        float: The float value of the helpfulness score, calculated as \"x / y\". Returns 0 if \"y\" is 0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nom, denom = x.split(\"/\")\n",
    "        return int(nom) / int(denom)\n",
    "    except (ValueError, ZeroDivisionError):\n",
    "        return 0\n",
    "\n",
    "df['review/helpfulness'] = df['review/helpfulness'].apply(handle_helpfulness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b74626",
   "metadata": {},
   "source": [
    "The price and score columns are stroing numeric values, the review has time in seconds. When it comes to helpfulness it was transformed to the float value that represents it.\n",
    "\n",
    "Coming back to the missing values before the set division, the last thing about them is the price. As it is a significant amount of data in the dataset it would not make sense to drop it. Taking into consideration that assigning a price of a small accessory to a brand new cellphone would distort the dataset, the missing values in this column will not be replaced with mean, median or mode. The products are stored in more or less an order (similiar products next to one another) so an optimal way to impute the missing values would be kNN method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53813654",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_missing_values = df[['product/price']]\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_features = imputer.fit_transform(features_with_missing_values)\n",
    "df['product/price'] = imputed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73381726",
   "metadata": {},
   "source": [
    "#### Division of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into anonymous and named\n",
    "df_anon = df[(df['review/userId'].isna()) & (df['review/profileName'].isna())]\n",
    "df_named = df[~(df['review/userId'].isna()) & ~(df['review/profileName'].isna())]\n",
    "\n",
    "# Deleting unnecessary columns from the anonymous reviews\n",
    "df_anon = df_anon.drop(columns=['review/userId', 'review/profileName'])\n",
    "\n",
    "# Resetting index\n",
    "df_named.reset_index(inplace=True, drop=True)\n",
    "df_anon.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Checking if everything went as expected\n",
    "print(f\"Missing values occurences in anonymous reviews dataset:\\n{df_anon.isna().sum()}\")\n",
    "print(f\"Missing values occurences in named reviews dataset:\\n{df_named.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572299b7",
   "metadata": {},
   "source": [
    "The analysis will focus on the named reviews but there will always be an available point of reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c003d3",
   "metadata": {},
   "source": [
    "#### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look on the prepared data\n",
    "df_named.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02224a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41570c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the columns with numercial and categorical variables\n",
    "numerical = ['product/price', 'review/helpfulness', 'review/score', 'review/time']\n",
    "categorical = ['product/productId', 'product/title', 'review/userId', 'review/profileName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b83a3",
   "metadata": {},
   "source": [
    "Summary and text would be difficult to visualize so those columns are not taken into consideration in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331c3ef",
   "metadata": {},
   "source": [
    "#### a. Named Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "fig, axs = plt.subplots(2, 2, figsize=[15, 15])\n",
    "fig.suptitle(\"Data distribution for Named Reviews\")\n",
    "\n",
    "max_counts = [df_named[col].value_counts().max() for col in numerical]\n",
    "for i, col in enumerate(df_named[numerical]):\n",
    "    sns.histplot(data=df_named, x=col, ax=axs[i//2, i%2], color='darkmagenta')\n",
    "    axs[i//2, i%2].set(title=col, xlabel='Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2c860",
   "metadata": {},
   "source": [
    "It is visible that most of the reviews are rather extremely helpful or extremely unhelpful, something in between is not seen very often. A similiar situation can be observed in the Score histogram but not to such extent (4.0 note is observed more often than 1.0). Majority of reviews has a score 5.0 which is a sign of good quality of the products. What is interesting is that most of the reviews were registered in 2007-2008 which is the time of Global Financial Crisis. It suggests that during this time people were carefully watching their expenses and looking and the quality of products more than usual. This could lead to the highest amount of the reviews on the plot. The plot which refers to the price is not very transparent, so in order to better understand the data there was a boxplot created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff372f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,6])\n",
    "sns.boxplot(x=df_named['product/price'], ax=ax, color='darkmagenta')\n",
    "ax.set(xlabel='Product Price', title=\"Boxplot for Product Price (Named Reviews)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e62d9",
   "metadata": {},
   "source": [
    "It is important to remember that more than a half of the price values were imputed by kNN algorithm so the results might not be 100% reliable. That is also the reason why outliers are not removed. Majority of the product is in the cheaper section, while more expensive products are bought less often - they are treated as outliers in this dataset. Half of the dataset (between first and third quartile) is represented by (15,35) range (approximately)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d4191",
   "metadata": {},
   "source": [
    "#### b. Anonymous Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "fig, axs = plt.subplots(2, 2, figsize=[15, 15])\n",
    "fig.suptitle(\"Data distribution for Anonymous Reviews\")\n",
    "\n",
    "max_counts = [df_anon[col].value_counts().max() for col in numerical]\n",
    "for i, col in enumerate(df_anon[numerical]):\n",
    "    sns.histplot(data=df_anon, x=col, ax=axs[i//2, i%2], color='darkmagenta')\n",
    "    axs[i//2, i%2].set(title=col, xlabel='Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd31834",
   "metadata": {},
   "source": [
    "The result are similar to those from Names Reviews dataset. The biggest difference is visible on the last plot - anonymous reviews were the most popular in 2004. It might prove that people in this time were not trusting the internet as much as they did in 2007-2008 and did not want to provide the personal data to any websites. It is also interesting to see that starting from 2008 the anonymous reviews are rarely observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c7f87",
   "metadata": {},
   "source": [
    "## Machine Learning analysis\n",
    "\n",
    "#### Natural Language Processing - data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3396fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare necessary tools\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses a given text by tokenizing it into words, converting all words to lowercase, \n",
    "    removing any non-alphabetic characters and stop words, and stemming the remaining words. \n",
    "    The processed words are then joined into a single string and returned.\n",
    "\n",
    "    Args:\n",
    "    text (str): A string of text to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "    str: The preprocessed text, consisting of stemmed words in lower case, with non-alphabetic characters and stop words removed and all words joined into a single string.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    words = [w for w in words if w.isalpha() and w not in stop_words]\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_named['text'] = df_named['review/summary'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08903c0",
   "metadata": {},
   "source": [
    "At the beginning of Natural Language Processing it is necessary to prepare the data - handle to stop words, stemming or non-alphabetic characters. The choice between Summary and Text column was not easy, but both of the columns contain natural language, so Summary was picked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b9fd3",
   "metadata": {},
   "source": [
    "#### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling\n",
    "df_named['sentiment'] = df_named['review/score'].apply(lambda score: 1 if score > 3 else 0)\n",
    "\n",
    "# Showing the basic information\n",
    "positive_reviews = df_named['sentiment'].sum() / len(df_named) * 100\n",
    "negative_reviews = 100 - positive_reviews\n",
    "print(f\"Percentage of positive reviews: {positive_reviews:.2f}%. Negative reviews: {negative_reviews:.2f}%\")\n",
    "\n",
    "# Preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_named['text'], df_named['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting the text data into a numerical representation using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Training and evaluating a logistic regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680e86f",
   "metadata": {},
   "source": [
    "After sentiment analysis it is really easy to see whether the product has a positive or negative review. This information is stored in the Sentiment column. Based on this column a machine learning model was trained. The model could have been based on various binary classification algorithms such as Decision Trees or SVM, but Logistic Regression was chosen. The evaluation showed that the model works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258984bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10% of the rows randomly\n",
    "sample_df = df_named.sample(frac=0.1, random_state=42)\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69a189",
   "metadata": {},
   "source": [
    "Because of comuptational reasons the decision about sampling was made. The next algorithms are going to be executed on a 10% randomly selected rows from the original dataset. Those algorithms should be performed on original dataset if the technical conditions are met. There was an attempt to choose a strategy with dividing the set to batches and then concatenating the results of manipulations on every single batch. However, this also unfortunately did not work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67efa0",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(sample_df['text'])\n",
    "\n",
    "# Trying to find optimal hyperparameters for the DBSCAN algorithm\n",
    "silhouette_scores = []\n",
    "for eps in np.arange(0.1, 1.0, 0.1):\n",
    "    for min_samples in range(2, 10):\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        dbscan.fit(X)\n",
    "        labels = dbscan.labels_\n",
    "        if np.max(labels) > 0: # ensure there is at least one cluster\n",
    "            score = silhouette_score(X, labels)\n",
    "            silhouette_scores.append((eps, min_samples, score))\n",
    "best_eps, best_min_samples, best_score = max(silhouette_scores, key=lambda x: x[2])\n",
    "print(f'Best hyperparameters: eps={best_eps}, min_samples={best_min_samples}, score={best_score}')\n",
    "\n",
    "# Fitting the DBSCAN with the found hyperparameters and showing the clusters\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "dbscan.fit(X)\n",
    "labels = dbscan.labels_\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0) # count the number of clusters\n",
    "print(f'Number of clusters: {n_clusters}')\n",
    "for i in range(n_clusters):\n",
    "    cluster_idx = labels == i\n",
    "    cluster_text = sample_df.loc[cluster_idx, 'review/summary']\n",
    "    print(f'Cluster {i}:')\n",
    "    print(cluster_text.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e2bcf",
   "metadata": {},
   "source": [
    "The results of clustering are not very satisfying when it comes to cluster number. 587 is a very large one and the author is aware of the possibly wrong results. There were attempts to use KMeans method and agglomerative clustering, however they ended up with worse results than presented DBSCAN (agglomerative clustering took a lot of time to execute and KMeans achieved the worst silhouette score). It might not be correct approach but Clustering is very important in this kind of analysis. However, in this specific case other algorithms are more reliable. The author will try to improve on this field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f96ea",
   "metadata": {},
   "source": [
    "#### Recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39231d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "product_titles = vectorizer.fit_transform(sample_df['product/title'])\n",
    "\n",
    "# Calculating similarity of the products\n",
    "cosine_sim_matrix = cosine_similarity(product_titles)\n",
    "\n",
    "def get_similar_products(product_id, n=5):\n",
    "    \"\"\"\n",
    "    Find the top n products that are most similar to the given product ID based on their titles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    product_id : str\n",
    "        The product ID to search for.\n",
    "    n : int, optional\n",
    "        The number of similar products to return (default is 5).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the top n products that are most similar to the given product ID.\n",
    "        The DataFrame contains two columns: 'product/productId' and 'product/title'.\n",
    "    \"\"\"\n",
    "    unique_products = sample_df.groupby('product/productId').first().reset_index()\n",
    "    idx = unique_products.index[unique_products['product/productId'] == product_id].tolist()[0]\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, _ in sim_scores[1:n+1]]\n",
    "    \n",
    "    return unique_products.loc[top_indices, ['product/productId', 'product/title']]\n",
    "\n",
    "# Example usage on 'B000JIK92C' product\n",
    "get_similar_products('B000JIK92C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f967d7d",
   "metadata": {},
   "source": [
    "This is a recommender system that returns top n products that are similar to the given one basen on their titles. This could be very useful to recommend the returned products to the users that bought the one passed to the function. It could increase the sales significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
