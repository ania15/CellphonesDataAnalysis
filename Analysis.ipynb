{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c2aef5",
   "metadata": {},
   "source": [
    "## Anna Kaniowska - Cellphones & Accessories dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505a6c1",
   "metadata": {},
   "source": [
    "The goal of this project is to extract as much information form the data set that can be obtained here - http://snap.stanford.edu/data/amazon/Cell_Phones_&_Accessories.txt.gz (source: http://snap.stanford.edu/data/web-Amazon-links.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed to perform the analysis\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.decomposition import PCA\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415de27",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A modified version of function available on the source page\n",
    "def parse(filename):\n",
    "    \"\"\"\n",
    "    Parses a gzipped text file and returns a list of dictionaries containing the parsed data.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The path to the gzipped text file to be parsed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing the parsed data.\n",
    "    \"\"\"\n",
    "    f = gzip.open(filename, 'rb')\n",
    "    entry = {}\n",
    "    data = []\n",
    "    for line in f:\n",
    "        l = line.decode('utf-8').strip()\n",
    "        colonPos = l.find(':')\n",
    "        if colonPos == -1:\n",
    "            data.append(entry)\n",
    "            entry = {}\n",
    "            continue\n",
    "        eName = l[:colonPos]\n",
    "        rest = l[colonPos+2:]\n",
    "        entry[eName] = rest\n",
    "    data.append(entry)\n",
    "    return data\n",
    "\n",
    "# Loading the dataset\n",
    "data = parse('Cell_Phones_&_Accessories.txt.gz')\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff9746",
   "metadata": {},
   "source": [
    "#### Getting to know the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c0f42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f536042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447791f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the dataset is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780ac8a",
   "metadata": {},
   "source": [
    "Taking a first look at the data, it is visible that it shows the reviews that customers gave to the products. The products are mainly cellphones and their accesories. The dataset is big - almost 79 000 rows is a significant amount of data. 10 columns provide information about the rated product, the customer and their opinion on the product. When it comes to technical details - it is necessary to change 'unknown' values to NaN in order to prepare data to further analysis. Checking the dataset for duplicated rows and dropping existing ones is also necessary because this is something that cannot be seen at first glance. Another conclusion is that the types of the columns are not necessarily correct (e.g. product/price should be stored as float), it is also needed to be corrected.\n",
    "\n",
    "## Feature Engineering & Exploratory Data Analysis\n",
    "\n",
    "#### Checking for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba20d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There is {df.duplicated().sum()} duplicated rows in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edc49b",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"unknown\", np.nan, inplace=True)\n",
    "\n",
    "# Analyzing the missing values occurences\n",
    "print(\"Missing values occurences:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Checking anonymous reviews (those where userId and profileName is missing)\n",
    "anon_reviews_perc = df['review/userId'].isna().sum()/df.shape[0] * 100\n",
    "print(f\"{anon_reviews_perc:.2f}% of the reviews are anonymously submitted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d2f306",
   "metadata": {},
   "source": [
    "The first conclusion is one row that can be safely deleted in each column (it is very likely that it is the same row for each of the columns). \\\n",
    "The second conclusion refers to anonymous reviews. When missing values are less than 5% of given feature, they can be safely deleted without having impact on further analysis. For now the data will be divided into to sets - first with anonymous reviews and second with named reviews. It may be useful to further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac16955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting columns with 1 missing value\n",
    "cols = ['product/productId', 'product/title', 'review/helpfulness', 'review/score', 'review/time', \\\n",
    "        'review/summary', 'review/text']\n",
    "df = df.dropna(subset=cols)\n",
    "print(f\"Shape of the dataset after dropping NaNs: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131debf",
   "metadata": {},
   "source": [
    "As expected, only one row of the data was deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc67d5e0",
   "metadata": {},
   "source": [
    "Before dividing dataset into two separate dataset it would be useful to correct the columns' types.\n",
    "\n",
    "#### Correcting columns types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product/price'] = pd.to_numeric(df['product/price'], errors='coerce')\n",
    "df['review/score'] = pd.to_numeric(df['review/score'], errors='coerce')\n",
    "df['review/time'] = pd.to_datetime(df['review/time'].astype(float), unit='s')\n",
    "\n",
    "def handle_helpfulness(x):\n",
    "    \"\"\"\n",
    "    Converts the string representation of helpfulness scores to a float value between 0 and 1.\n",
    "\n",
    "    Parameters:\n",
    "        helpfulness (str): The string representation of helpfulness scores, in the format \"x/y\",\n",
    "        where \"x\" is the number of users who found the review helpful and \"y\" is the total number of votes.\n",
    "\n",
    "    Returns:\n",
    "        float: The float value of the helpfulness score, calculated as \"x / y\". Returns 0 if \"y\" is 0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nom, denom = x.split(\"/\")\n",
    "        return int(nom) / int(denom)\n",
    "    except (ValueError, ZeroDivisionError):\n",
    "        return 0\n",
    "\n",
    "df['review/helpfulness'] = df['review/helpfulness'].apply(handle_helpfulness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b74626",
   "metadata": {},
   "source": [
    "The price and score columns are stroing numeric values, the review has time in seconds. When it comes to helpfulness it was transformed to the float value that represents it.\n",
    "\n",
    "Coming back to the missing values before the set division, the last thing about them is the price. As it is a significant amount of data in the dataset it would not make sense to drop it. Taking into consideration that assigning a price of a small accessory to a brand new cellphone would distort the dataset, the missing values in this column will not be replaced with mean, median or mode. The products are stored in more or less an order (similiar products next to one another) so an optimal way to impute the missing values would be kNN method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53813654",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_missing_values = df[['product/price']]\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_features = imputer.fit_transform(features_with_missing_values)\n",
    "df['product/price'] = imputed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73381726",
   "metadata": {},
   "source": [
    "#### Division of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into anonymous and named\n",
    "df_anon = df[(df['review/userId'].isna()) & (df['review/profileName'].isna())]\n",
    "df_named = df[~(df['review/userId'].isna()) & ~(df['review/profileName'].isna())]\n",
    "\n",
    "# Deleting unnecessary columns from the anonymous reviews\n",
    "df_anon = df_anon.drop(columns=['review/userId', 'review/profileName'])\n",
    "\n",
    "# Resetting index\n",
    "df_named.reset_index(inplace=True, drop=True)\n",
    "df_anon.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Checking if everything went as expected\n",
    "print(f\"Missing values occurences in anonymous reviews dataset:\\n{df_anon.isna().sum()}\")\n",
    "print(f\"Missing values occurences in named reviews dataset:\\n{df_named.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572299b7",
   "metadata": {},
   "source": [
    "The analysis will focus on the named reviews but the anonymous ones will always be an available point of reference. This decision is supported by the fact that named reviews can be treated as more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c003d3",
   "metadata": {},
   "source": [
    "#### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d84449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look on the prepared data\n",
    "df_named.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41570c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the columns with numercial and categorical variables\n",
    "numerical = ['product/price', 'review/helpfulness', 'review/score', 'review/time']\n",
    "categorical = ['product/productId', 'product/title', 'review/userId', 'review/profileName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b83a3",
   "metadata": {},
   "source": [
    "Summary and text would be difficult to visualize so those columns are not taken into consideration in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331c3ef",
   "metadata": {},
   "source": [
    "#### a. Named Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "fig, axs = plt.subplots(2, 2, figsize=[15, 15])\n",
    "fig.suptitle(\"Data distribution for Named Reviews\")\n",
    "\n",
    "max_counts = [df_named[col].value_counts().max() for col in numerical]\n",
    "for i, col in enumerate(df_named[numerical]):\n",
    "    sns.histplot(data=df_named, x=col, ax=axs[i//2, i%2], color='darkmagenta')\n",
    "    axs[i//2, i%2].set(title=col, xlabel='Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2c860",
   "metadata": {},
   "source": [
    "It is visible that most of the reviews are rather extremely helpful or extremely unhelpful, something in between is not seen very often. A similiar situation can be observed in the Score histogram but not to such extent (4.0 note is observed more often than 1.0). Majority of reviews has a score 5.0 which is a sign of good quality of the products. \\ \n",
    "What is interesting is that most of the reviews were registered in 2007-2008 which is the time of Global Financial Crisis. It suggests that during this time people were carefully watching their expenses and looking and the quality of products more than usual. This could lead to the highest amount of the reviews on the plot. There is another theory why this peak took place. In 2007 Amazon experienced servers outages that caused about 2 hours of downtime on the platform. It was a famous case, so when people talked about, they might have decided to use their services and write some reviews. The topics are not directly related but they both refer to Amazon websites so there might be a correlation. \\\n",
    "The plot which refers to the price is not very transparent, so in order to better understand the data there was a boxplot created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff372f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,6])\n",
    "sns.boxplot(x=df_named['product/price'], ax=ax, color='darkmagenta')\n",
    "ax.set(xlabel='Product Price', title=\"Boxplot for Product Price (Named Reviews)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e62d9",
   "metadata": {},
   "source": [
    "It is important to remember that more than a half of the price values were imputed by kNN algorithm so the results might not be 100% reliable. That is also the reason why outliers are not removed. Majority of the product is in the cheaper section, while more expensive products are bought less often - they are treated as outliers in this dataset. Half of the dataset (between first and third quartile) is represented by (15,35) range (approximately)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d4191",
   "metadata": {},
   "source": [
    "#### b. Anonymous Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "fig, axs = plt.subplots(2, 2, figsize=[15, 15])\n",
    "fig.suptitle(\"Data distribution for Anonymous Reviews\")\n",
    "\n",
    "max_counts = [df_anon[col].value_counts().max() for col in numerical]\n",
    "for i, col in enumerate(df_anon[numerical]):\n",
    "    sns.histplot(data=df_anon, x=col, ax=axs[i//2, i%2], color='darkmagenta')\n",
    "    axs[i//2, i%2].set(title=col, xlabel='Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd31834",
   "metadata": {},
   "source": [
    "The results are similar to those from Names Reviews dataset. The biggest difference is visible on the last plot - anonymous reviews were the most popular in 2004. It might prove that people in this time were not trusting the internet as much as they did in 2007-2008 and did not want to provide the personal data to any websites. It is also interesting to see that starting from 2008 the anonymous reviews are rarely observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c7f87",
   "metadata": {},
   "source": [
    "## Machine Learning analysis\n",
    "\n",
    "In this section there will appear several machine learning techiniques used to get as much information form the data as possible.\n",
    "\n",
    "#### Natural Language Processing - data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3396fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare necessary tools\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses a given text by tokenizing it into words, converting all words to lowercase, \n",
    "    removing any non-alphabetic characters and stop words, and stemming the remaining words. \n",
    "    The processed words are then joined into a single string and returned.\n",
    "\n",
    "    Args:\n",
    "    text (str): A string of text to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "    str: The preprocessed text, consisting of stemmed words in lower case, with non-alphabetic characters and stop words removed and all words joined into a single string.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    words = [w for w in words if w.isalpha() and w not in stop_words]\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_named['text'] = df_named['review/summary'].apply(preprocess_text)\n",
    "df_anon['text'] = df_anon['review/summary'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34fe23",
   "metadata": {},
   "source": [
    "At the beginning of Natural Language Processing it is necessary to prepare the data - handle to stop words, stemming or non-alphabetic characters. The choice between Summary and Text column was not easy, but both of the columns contain natural language, so Summary was picked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd943842",
   "metadata": {},
   "source": [
    "#### Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8732707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bag of words from the preprocessed text\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(df_named['text'])\n",
    "\n",
    "# Extracting the frequency of each word\n",
    "word_freq = dict(zip(vectorizer.get_feature_names_out(), bag_of_words.sum(axis=0).tolist()[0]))\n",
    "top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Displaying top 10\n",
    "print(\"Most common words:\")\n",
    "for word, freq in top_words:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8783e",
   "metadata": {},
   "source": [
    "After this simple analysis it is visible that the most frequently used words are adjectives and adverbs like great, good, best. However, the words describing products like phone, case, headset or product itself are equally important. This confirms that the reviews are focused on rating the products and are not randomly written sentences. However, there are some typos like 'batteri' in them. It might suggest that not all of the customers are english native speakers which is very possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing sentiment using TextBlob and VADER\n",
    "df_named['polarity'] = df_named['review/text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df_named['vader_scores'] = df_named['review/text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Performing topic modeling using LDA\n",
    "texts = [doc.split() for doc in df_named['text']]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "topics = lda_model.print_topics()\n",
    "\n",
    "# Displaying the topics\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    \n",
    "# Visualizing the results\n",
    "sns.histplot(data=df_named, x='polarity', kde=True, color='magenta')\n",
    "plt.title(\"Distribution of sentiment polarity\")\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df_named, x='vader_scores', kde=True, color='magenta')\n",
    "plt.title(\"Distribution of sentiment scores (VADER)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533dc840",
   "metadata": {},
   "source": [
    "To get to know the text charasteristics better LDA (Latent Dirichlet Allocation) was used. The model assumes that documents are made up of multiple topics, and each topic is made up of a set of words. The algorithm takes a corpus of documents as input and tries to identify the underlying topics based on the frequency of words within each document. LDA assumes that each document contains a mixture of topics and each word in the document is associated with one of the topics. \\\n",
    "The algorithm shows 5 indentified topics with top 10 words in each of them. The topics are usually based on the reviewed product or some common features of given product. \\\n",
    "The first plot shows sentiment polarity - in this dataset the reviews are rather positive. This is proven by the fact that the plot resembles normal distribution with mean at 0.25 value. Sentiment polarity ranges from -1 (negative sentiment) to 1 (positive sentiment) where 0 is neutral. The peak on 0.0 can be also observed so there is a significant amount of neutral reviews too. \\\n",
    "The second plot show the VADER (Valence Aware Dictionary and sEntiment Reasoner) analysis. It is based on vader score which also ranges from -1 to 1 based on negativity or positivity of analyzed text. This method uses a dictionary with scores for many words and expressions and, what's more an algorithm that takes the context into consideration. It also shows that positive reviews are the majority of the dataset and that neutral reviews are standing out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b9fd3",
   "metadata": {},
   "source": [
    "#### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling\n",
    "df_named['sentiment'] = df_named['review/score'].apply(lambda score: 1 if score > 3 else 0)\n",
    "\n",
    "# Showing the basic information\n",
    "positive_reviews = df_named['sentiment'].sum() / len(df_named) * 100\n",
    "negative_reviews = 100 - positive_reviews\n",
    "print(f\"Percentage of positive reviews: {positive_reviews:.2f}%. Negative reviews: {negative_reviews:.2f}%\")\n",
    "\n",
    "# Preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_named['text'], df_named['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting the text data into a numerical representation using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Training and evaluating a logistic regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b64d8",
   "metadata": {},
   "source": [
    "After sentiment analysis it is really easy to see whether the product has a positive or negative review. The perecentages of positive and negatice reviews are a confirmation for the conclusions from sentiment histograms. This information is stored in the Sentiment column. Based on this column a machine learning model was trained. The model could have been based on various binary classification algorithms such as Decision Trees or SVM, but Logistic Regression was chosen. The evaluation showed that the model works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258984bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 33% of the rows randomly\n",
    "sample_df = df_named.sample(frac=0.33, random_state=42)\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb4a02",
   "metadata": {},
   "source": [
    "Because of computational reasons the decision about sampling was made. Some of the next algorithms are going to be executed on a 33% randomly selected rows from the original dataset. Those algorithms should be performed on original dataset if the technical conditions are met. There was an attempt to choose a strategy with dividing the set to batches and then concatenating the results of manipulations on every single batch. However, this also unfortunately did not work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67efa0",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_anon['text'])\n",
    "\n",
    "# Trying to find optimal hyperparameters for the DBSCAN algorithm\n",
    "silhouette_scores = []\n",
    "for eps in np.arange(0.1, 1.0, 0.1):\n",
    "    for min_samples in range(2, 10):\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        dbscan.fit(X)\n",
    "        labels = dbscan.labels_\n",
    "        if np.max(labels) > 0: # ensure there is at least one cluster\n",
    "            score = silhouette_score(X, labels)\n",
    "            silhouette_scores.append((eps, min_samples, score))\n",
    "best_eps, best_min_samples, best_score = max(silhouette_scores, key=lambda x: x[2])\n",
    "print(f'Best hyperparameters: eps={best_eps}, min_samples={best_min_samples}, score={best_score}')\n",
    "\n",
    "# Fitting the DBSCAN with the found hyperparameters and showing the clusters\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "dbscan.fit(X)\n",
    "labels = dbscan.labels_\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0) # count the number of clusters\n",
    "print(f'Number of clusters: {n_clusters}')\n",
    "for i in range(n_clusters):\n",
    "    cluster_idx = labels == i\n",
    "    cluster_text = df_anon.loc[cluster_idx, 'review/summary']\n",
    "    print(f'Cluster {i}:')\n",
    "    print(cluster_text.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2d27a",
   "metadata": {},
   "source": [
    "The results of clustering were not very satisfying on the sample_df. There were attempts to use KMeans method and agglomerative clustering, however they ended up with worse results than presented DBSCAN (agglomerative clustering took a lot of time to execute and KMeans achieved the worst silhouette score). That is why the author decided to present clustering on the dataset with anonymous reviews. Similarly to previous attempts there are a lot of clusters created and not all of them are correctly grouped. Also the score is not satisfying. It could be a great start to further analysis but the author does not have the skills yet (but is willing to learn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f96ea",
   "metadata": {},
   "source": [
    "#### Recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39231d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "product_titles = vectorizer.fit_transform(sample_df['product/title'])\n",
    "\n",
    "# Calculating similarity of the products\n",
    "cosine_sim_matrix = cosine_similarity(product_titles)\n",
    "\n",
    "def get_similar_products(product_id, n=5):\n",
    "    \"\"\"\n",
    "    Find the top n products that are most similar to the given product ID based on their titles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    product_id : str\n",
    "        The product ID to search for.\n",
    "    n : int, optional\n",
    "        The number of similar products to return (default is 5).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the top n products that are most similar to the given product ID.\n",
    "        The DataFrame contains two columns: 'product/productId' and 'product/title'.\n",
    "    \"\"\"\n",
    "    unique_products = sample_df.groupby('product/productId').first().reset_index()\n",
    "    idx = unique_products.index[unique_products['product/productId'] == product_id].tolist()[0]\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, _ in sim_scores[1:n+1]]\n",
    "    \n",
    "    return unique_products.loc[top_indices, ['product/productId', 'product/title']]\n",
    "\n",
    "# Example usage on 'B000JIK92C' product\n",
    "get_similar_products('B000JIK92C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7263a",
   "metadata": {},
   "source": [
    "This is a recommender system that returns top n products that are similar to the given one basen on their titles. This could be very useful to recommend the returned products to the users that bought the one passed to the function. It could increase the sales significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de664e9",
   "metadata": {},
   "source": [
    "#### Time Series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_named.set_index('review/time', inplace=True)\n",
    "# Resampling the data by month and calculating mean sentiment score and number of reviews\n",
    "df_monthly = df_named.resample('M').agg({'vader_scores': 'mean', 'review/userId': 'count'})\n",
    "\n",
    "# Plotting mean sentiment score and number of reviews over time\n",
    "fig, axs = plt.subplots(figsize=[12,6])\n",
    "axs1 = axs.twinx()\n",
    "sns.lineplot(x=df_monthly.index, y=df_monthly['vader_scores'], ax=axs, color='steelblue')\n",
    "sns.lineplot(x=df_monthly.index, y=df_monthly['review/userId'], ax=axs1, color='magenta')\n",
    "axs.set(title=\"Sentiment and Review Trends Over Time\", xlim=[df_monthly.index[0], df_monthly.index[-1]], ylim = [0, 1.05], ylabel='Mean Sentiment Score')\n",
    "axs1.set(ylim=[-100,3000], ylabel='Number of Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace2c46",
   "metadata": {},
   "source": [
    "Approaching the data form the other side, a time series is used to show how the amount of reviews and their mean sentiment changed overtime. The most interesting facts are that the peak of reviews amount took place in 2007 and that mean sentiment score has a downward trend. \\\n",
    "At the very beginning the mean sentiment was very unstable but always above 0 which means that the reviews were rather positive the whole time. Later the values happened to be more stabilized and it is clearly visible than the mean drops each year. \\\n",
    "Coming back to the number of reviews, after the peak in 2007 the values also dropped but at the end of the dataset (circa 2013) they peaked again. 2013 was the year when Amazon introduced AmazonFresh (it offers the delivery of groceries including fresh fruits and vegetables). This is not connected to the topic of the dataset but because of this release Amazon was all over the news and it might have reminded people to log in and leave a review or two. However, this is only an uncertain suggestion and can be treated as an interesting fact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e2483",
   "metadata": {},
   "source": [
    "#### DImensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of the reviews and vectorizing it using TF-IDF\n",
    "reviews = df_named['text'].tolist()\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(reviews)\n",
    "\n",
    "# Reducing the dimensionality using PCA and visualizing results\n",
    "pca = PCA(n_components=3)\n",
    "pca_matrix = pca.fit_transform(tfidf_matrix.toarray())\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_matrix[:,0], pca_matrix[:,1], pca_matrix[:,2], alpha=0.2)\n",
    "ax.set(xlabel='PC1', ylabel='PC2', zlabel='PC3', \\\n",
    "       title=\"Visualization of Review Data using PCA Dimensionality Reduction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12d5e3",
   "metadata": {},
   "source": [
    "The PCA algorithm reduces the TF-IDF matrix to 3 dimensions - each representing another variable. \\\n",
    "In this PCA plot the relationships between the variables are showed, each point represents a review, and the position of the point in the plot indicates how similar or dissimilar it is to other reviews. The distance between two points indicates how different their underlying features are. \\\n",
    "It is visible that there are a lot of groups of points clustered together which means that there are sets of similar reviews. Clustering can be done on this data but, as mentioned before, it is not so easy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f4220",
   "metadata": {},
   "source": [
    "#### Visualzations more or less related to previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038efb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating wordcloud image based on the reviews\n",
    "text = \" \".join(review for review in df_named['review/text'])\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2d019",
   "metadata": {},
   "source": [
    "The wordmap shows the most popular words in review and helps to understand the most common topics. The result is not very surprising - the words revolve around cellphones, their accesories and the quality of the products. However, it is useful to see such visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation between the variables\n",
    "df_named['review/length'] = df_named['review/text'].apply(len) # Length of review might be an interesting variable\n",
    "df_heatmap = df_named[['review/length', 'review/helpfulness', 'vader_scores', 'polarity']].copy()\n",
    "corr_matrix = df_heatmap.corr()\n",
    "sns.set(style=\"white\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"rocket_r\")\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92767ea",
   "metadata": {},
   "source": [
    "The heatmap unfortunately does not provide many interesting patterns. The visible correlation is the one between vader scores and polarity - it is known that they are directly related. Unfortunately, there are not any significant correlations beween other variables. Only review helpfulness is moderately correlated to the length of the review - the longer the review is, the more helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1197fb9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d800c",
   "metadata": {},
   "source": [
    "The dataset provided a lot of information about the cellphones and their accesories reviews submitted on Amazon website. The analyzed reviews were collected between circa 2000 and 2013. At the beginning customers were tending to leave the reviews anonymously but later (2006/2007) that changed. The analysis focused on the reviews that were not anonymous. Overall, the majority of the reviews were positive. Several machine learning alogirthms were used to perform the analysis. In addition to the machine learning algorithms, several exploratory data analysis techniques were applied to gain insights into the data, including sentiment analysis, topic modeling, and dimensionality reduction. The results of the analysis showed that the most commonly mentioned topics in the reviews were related to product features such as battery life, screen size, and sound quality. The dataset can be used to inform product development and marketing strategies for cellphone and accessory manufacturers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
